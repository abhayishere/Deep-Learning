{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_introduction_to_nlp_in_tensorflow_video.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/tensorflow-deep-learning/blob/main/video_notebooks/08_introduction_to_nlp_in_tensorflow_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkhpvcnZiNkb"
      },
      "source": [
        "# Introduction to NLP Fundamentals in TensorFlow\n",
        "\n",
        "NLP has the goal of deriving informaton out of natural language (could be seqeuences text or speech).\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq).\n",
        "\n",
        "> üìñ **Resource:** See all course materials, resources and extra-curriculum for this notebook on GitHub: https://github.com/mrdbourke/tensorflow-deep-learning/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F251SjqZimVF"
      },
      "source": [
        "## Check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1dVFu5Jis9Z",
        "outputId": "5d1ecb7e-b86a-4d27-8707-de696d5ce273"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-ffcdd345-2451-5781-5b76-e477b5a7568d)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qrnNJ_4iuX-"
      },
      "source": [
        "## Get helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xC2eRi-Ti6Bt",
        "outputId": "bde710cd-83d8-4b50-aecd-707c1dcfb0ca"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-15 12:17:22--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‚Äòhelper_functions.py‚Äô\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-08-15 12:17:22 (98.6 MB/s) - ‚Äòhelper_functions.py‚Äô saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8MQn_DwjSlJ"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples of Tweets labelled as diaster or not diaster).\n",
        "\n",
        "See the original source here: https://www.kaggle.com/c/nlp-getting-started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuFNZ6zvjW-J",
        "outputId": "d04a898a-859d-4eca-91ec-fc4e5e559f6b"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-15 12:17:24--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.135.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.135.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‚Äònlp_getting_started.zip‚Äô\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2021-08-15 12:17:24 (144 MB/s) - ‚Äònlp_getting_started.zip‚Äô saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I5zOcnvj4NO"
      },
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "To visualize our text samples, we first have to read them in, one way to do so would be to use Python: https://realpython.com/read-write-files-python/\n",
        "\n",
        "But I prefer to get visual straight away.\n",
        "\n",
        "So another way to do this is to use pandas..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "WMK3xqK8kqQL",
        "outputId": "039effe6-b736-4fd8-e65a-d51464aeefaa"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "ng4p6stElbl4",
        "outputId": "d0db03b3-677b-4d44-e7eb-d117834c17ff"
      },
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42) \n",
        "train_df_shuffled.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ¬â√õ√èThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "dBUTSefKljdb",
        "outputId": "86faaa94-f570-4d5c-a522-bc66181da5d5"
      },
      "source": [
        "# What does the test dataframe look like?\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rCFdfq7mJGs",
        "outputId": "75d4760b-4205-4c9d-9008-cd9ce4c0da37"
      },
      "source": [
        "# How many examples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5wrCzWCmS9P",
        "outputId": "10a67f6f-cbf4-4fd0-b773-8db5fdfc9721"
      },
      "source": [
        "# How many total samples?\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHqct-_WmzSp",
        "outputId": "27bde551-f6c3-4ee6-f80c-5e04ce78bb33"
      },
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real diaster)\" if target > 0 else \"(not real diaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target: 1 (real diaster)\n",
            "Text:\n",
            "Raw Video: Dust Storm Rolls Through Texas http://t.co/QllkOfdyzX http://t.co/rGjJuMnNah\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real diaster)\n",
            "Text:\n",
            "@greateranglia I know the cow incident not yr fault by how where they on the line could of caused a derailment\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real diaster)\n",
            "Text:\n",
            "1.9 earthquake occurred 15km E of Anchorage Alaska at 00:11 UTC! #earthquake #Anchorage http://t.co/QFyy5aZIFx\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real diaster)\n",
            "Text:\n",
            "#IDFire Parker Ridge Fact Sheet Aug 6 2015 (Parker Ridge Wildfire): Information Phone: 208-267-6773 Email: pa... http://t.co/ZggpaCjP7D\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real diaster)\n",
            "Text:\n",
            "Thief Broke Front Window Of Hicksville Store Stole 50 Cell Phones; Fled Crashed Into... http://t.co/6odNBttPSq\n",
            "\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZEKNKZOn0A8"
      },
      "source": [
        "### Split data into training and validation sets\n",
        "\n",
        "We want to be able to see how our model is performing on unseen data whilst it trains.\n",
        "\n",
        "And because the testing dataset doesn't have labels, we'll have to create a validation dataset to evaluate on (the model won't see the validation dataset during training so we can use its samples and labels to evaluate our model's performance)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRurDp_XpEv_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBSr2LTvpRQm"
      },
      "source": [
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # use 10% of training data for validation split\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxpYGpF5pxiM",
        "outputId": "c6d57505-b71c-46a6-9e87-42f03558b21b"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1xC2MWxp5Rj",
        "outputId": "8c901fb3-e69f-45b8-b83a-2e141578df22"
      },
      "source": [
        "# Check the first 10 samples \n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Td1h4t5p7ST"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert your text to numbers.\n",
        "\n",
        "There are a few ways to do this, namely:\n",
        "* Tokenziation - direct mapping of token (a token could be a word or a character) to number\n",
        "* Embedding - create a matrix of feature vector for each token (the size of the feature vector can be defined and this embedding can be learned)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BI3K0U_xBtu6"
      },
      "source": [
        "### Text vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_hj9h10FJ56",
        "outputId": "cccae613-055a-4e39-fd71-8deb6323d632"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blJWemjwFIP-"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # how many words in the vocabulary (automatically add <OOV>)\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    split=\"whitespace\",\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None, # how long do you want your sequences to be?\n",
        "                                    pad_to_max_tokens=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wxF2xv-H4xB",
        "outputId": "e0907bc8-a684-4a0c-df51-7297bc801e03"
      },
      "source": [
        "len(train_sentences[0].split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjPouAI-FR0c",
        "outputId": "32692497-dcf2-4b7f-a014-5db32389da6c"
      },
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPPKoQ2uIBuY"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does a model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5TD-rndImmo"
      },
      "source": [
        "# Fit the text vectorizer instance to the training data using the adapt() method\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-ETwZ92JiOx",
        "outputId": "63de63cf-893a-40c1-bcaf-ae24eb44e83c"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIvgQw3MFjy4",
        "outputId": "3e89fae6-ca76-4253-a7a3-b4e76b9f8526"
      },
      "source": [
        "random_sentence = random.choice(train_sentences)\n",
        "print(random_sentence)\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Oh the usual. Mass murder and world domination plans over coffee. How's your day going?\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 392,    2, 2238,  157,  315,    7,  107,    1,  645,   60, 1542,\n",
              "           1,   33,  101,  104]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tacucdc7F9X4",
        "outputId": "e54ff1bd-2697-4394-bfc7-cd11917a8fa3"
      },
      "source": [
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5]\n",
        "top_5_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'the', 'a', 'in']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOIylar0Gg1v",
        "outputId": "02adbf5e-dad4-43d1-c5f1-f107428b92dc"
      },
      "source": [
        "bottom_5_words = words_in_vocab[-5:]\n",
        "bottom_5_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpH8hAiKG68A"
      },
      "source": [
        "##Creating an embedding using embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7t07U6DJLQG"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim = max_vocab_length,\n",
        "                             output_dim = 128,\n",
        "                             input_length = max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0Viui4sJ2Ox",
        "outputId": "eb1f98fd-f837-4474-916a-a3e0cb27a7dc"
      },
      "source": [
        "random_sentence = random.choice(train_sentences)\n",
        "print(random_sentence)\n",
        "\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NHS England announces new plan to meet emergency care targets http://t.co/0x2BIEqXPV\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.00451935,  0.03723775, -0.03475238, ...,  0.02113981,\n",
              "          0.00747805, -0.04684435],\n",
              "        [-0.03130349, -0.03065364, -0.01378814, ..., -0.01232495,\n",
              "         -0.04042579,  0.00072727],\n",
              "        [ 0.01726986,  0.03136216, -0.01655392, ..., -0.03045288,\n",
              "          0.00338695,  0.0399174 ],\n",
              "        ...,\n",
              "        [ 0.00434946, -0.04079541,  0.04726494, ...,  0.00665817,\n",
              "         -0.01822245,  0.02419044],\n",
              "        [ 0.00434946, -0.04079541,  0.04726494, ...,  0.00665817,\n",
              "         -0.01822245,  0.02419044],\n",
              "        [ 0.00434946, -0.04079541,  0.04726494, ...,  0.00665817,\n",
              "         -0.01822245,  0.02419044]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzYoACiAKbto"
      },
      "source": [
        "#Different experimental models\n",
        "1. Naive baeys baseline model\n",
        "2. feed forward neural network (dense network)\n",
        "3. LSTM model\n",
        "4. GRU model\n",
        "5. bidirectional LSTM model\n",
        "6. 1D convolutional neural netwokr\n",
        "7. tfhub pretrained model(transfer learning)\n",
        "8. same as above but with 10% of input data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGPhUapxc59z"
      },
      "source": [
        "##Model 1 naive bayes baseline model\n",
        "using multinomial naive bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx6X2YO9c_TC",
        "outputId": "d29ce3e6-0d74-4b8c-94b9-256e0e3a2101"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\",TfidfVectorizer()),\n",
        "                    (\"clf\",MultinomialNB())\n",
        "])\n",
        "\n",
        "model_0.fit(train_sentences,train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99naB7vfdibI",
        "outputId": "c0b5b539-9050-4f85-baf3-d408961bedbe"
      },
      "source": [
        "baseline_score = model_0.score(val_sentences,val_labels)\n",
        "print(\"Out base line model achieves an accuracy of\",baseline_score*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Out base line model achieves an accuracy of 79.26509186351706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnusQUPhegXP",
        "outputId": "32bc42bc-43fa-4e3c-8881-f7e0a5c8f66d"
      },
      "source": [
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnMxnHAbewBw"
      },
      "source": [
        "###Creating an evaluation function for our model experiments\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAf2qDgZojJQ"
      },
      "source": [
        "from sklearn.metrics import accuracy_score,precision_recall_fscore_support\n",
        "def calculate_results(y_true,y_pred):\n",
        "  model_accuracy = accuracy_score(y_true,y_pred)\n",
        "  model_precision,model_recall,model_f1,_ = precision_recall_fscore_support(y_true,y_pred)\n",
        "  model_results = {\"accuracy\":model_accuracy,\n",
        "                   \"precision\":model_precision,\n",
        "                   \"recall\":model_recall,\n",
        "                   \"f1\":model_f1}\n",
        "  return model_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MntvAjiXpoLG",
        "outputId": "f8eef051-574c-45c7-b4da-51984fd59dd5"
      },
      "source": [
        "baseline_results = calculate_results(val_labels,baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7926509186351706,\n",
              " 'f1': array([0.83010753, 0.73400673]),\n",
              " 'precision': array([0.74806202, 0.88617886]),\n",
              " 'recall': array([0.93236715, 0.62643678])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl-UpGT1pwUF"
      },
      "source": [
        "###Model 1: A simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KvIBlEqte7F"
      },
      "source": [
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "save_dir = \"model_logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1ATXXgwt1Bg"
      },
      "source": [
        "#building model using functional api\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,),\n",
        "                     dtype = tf.string)\n",
        "x = text_vectorizer(inputs) #turn thee input text into numbers\n",
        "x = embedding(x)#turn numbers into embedding\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_1 = tf.keras.Model(inputs,outputs,name=\"model_1_dense\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_I1R6rvub3U"
      },
      "source": [
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu-DHazX0E1l",
        "outputId": "fdb09cf1-70d0-4b26-a6b9-63b3c3985012"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKatcwiyynRS",
        "outputId": "a0a10bc7-1c3a-461c-c426-b787c4789783"
      },
      "source": [
        "model_1.fit(train_sentences,\n",
        "            train_labels,\n",
        "            epochs=5,\n",
        "            validation_data=(val_sentences,val_labels),\n",
        "            callbacks=[create_tensorboard_callback(dir_name=save_dir,\n",
        "                                                   experiment_name=\"model_1_dense\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20210815-121733\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 16ms/step - loss: 0.6125 - accuracy: 0.6938 - val_loss: 0.5388 - val_accuracy: 0.7585\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.4445 - accuracy: 0.8154 - val_loss: 0.4754 - val_accuracy: 0.7822\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.3495 - accuracy: 0.8610 - val_loss: 0.4580 - val_accuracy: 0.7913\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.2869 - accuracy: 0.8904 - val_loss: 0.4632 - val_accuracy: 0.7887\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 13ms/step - loss: 0.2395 - accuracy: 0.9132 - val_loss: 0.4808 - val_accuracy: 0.7861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff7a8150e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzaI6sj0zEA-",
        "outputId": "335d1220-954a-41b6-a90e-699e1839b872"
      },
      "source": [
        "model_1.evaluate(val_sentences,val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7861\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4807831645011902, 0.7860892415046692]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUN6M2TtzcoF",
        "outputId": "fa9bbcb6-b21a-4aac-869e-b5e727d7ecd9"
      },
      "source": [
        "model_1_pred_prob = model_1.predict(val_sentences)\n",
        "model_1_pred_prob[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.34694064], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7NaiTQt0nmU"
      },
      "source": [
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_prob))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN00_KPD1ciF",
        "outputId": "7f33aef2-905b-4c63-f713-c5d6c6b4a8c6"
      },
      "source": [
        "model_1_results = calculate_results(val_labels, model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7860892388451444,\n",
              " 'f1': array([0.81828317, 0.7400319 ]),\n",
              " 'precision': array([0.75983437, 0.83154122]),\n",
              " 'recall': array([0.88647343, 0.66666667])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19TOoW931q6H",
        "outputId": "83a37efd-924f-446a-91d8-27221828eb62"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7926509186351706,\n",
              " 'f1': array([0.83010753, 0.73400673]),\n",
              " 'precision': array([0.74806202, 0.88617886]),\n",
              " 'recall': array([0.93236715, 0.62643678])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4PN5-CK12lQ"
      },
      "source": [
        "##Visualizing learned embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiccEGBMDqrq",
        "outputId": "d48d0809-17d2-4ed7-8ac4-602df104519d"
      },
      "source": [
        "words_in_vocab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " 'the',\n",
              " 'a',\n",
              " 'in',\n",
              " 'to',\n",
              " 'of',\n",
              " 'and',\n",
              " 'i',\n",
              " 'is',\n",
              " 'for',\n",
              " 'on',\n",
              " 'you',\n",
              " 'my',\n",
              " 'with',\n",
              " 'it',\n",
              " 'that',\n",
              " 'at',\n",
              " 'by',\n",
              " 'this',\n",
              " 'from',\n",
              " 'be',\n",
              " 'are',\n",
              " 'was',\n",
              " 'have',\n",
              " 'like',\n",
              " 'as',\n",
              " 'up',\n",
              " 'so',\n",
              " 'just',\n",
              " 'but',\n",
              " 'me',\n",
              " 'im',\n",
              " 'your',\n",
              " 'not',\n",
              " 'amp',\n",
              " 'out',\n",
              " 'its',\n",
              " 'will',\n",
              " 'an',\n",
              " 'no',\n",
              " 'has',\n",
              " 'fire',\n",
              " 'after',\n",
              " 'all',\n",
              " 'when',\n",
              " 'we',\n",
              " 'if',\n",
              " 'now',\n",
              " 'via',\n",
              " 'new',\n",
              " 'more',\n",
              " 'get',\n",
              " 'or',\n",
              " 'about',\n",
              " 'what',\n",
              " 'he',\n",
              " 'people',\n",
              " 'news',\n",
              " 'been',\n",
              " 'over',\n",
              " 'one',\n",
              " 'how',\n",
              " 'dont',\n",
              " 'they',\n",
              " 'who',\n",
              " 'into',\n",
              " 'were',\n",
              " 'do',\n",
              " 'us',\n",
              " '2',\n",
              " 'can',\n",
              " 'video',\n",
              " 'emergency',\n",
              " 'there',\n",
              " 'disaster',\n",
              " 'than',\n",
              " 'police',\n",
              " 'would',\n",
              " 'his',\n",
              " 'still',\n",
              " 'her',\n",
              " 'some',\n",
              " 'body',\n",
              " 'storm',\n",
              " 'crash',\n",
              " 'burning',\n",
              " 'suicide',\n",
              " 'back',\n",
              " 'man',\n",
              " 'california',\n",
              " 'why',\n",
              " 'time',\n",
              " 'them',\n",
              " 'had',\n",
              " 'buildings',\n",
              " 'rt',\n",
              " 'first',\n",
              " 'cant',\n",
              " 'see',\n",
              " 'got',\n",
              " 'day',\n",
              " 'off',\n",
              " 'our',\n",
              " 'going',\n",
              " 'nuclear',\n",
              " 'know',\n",
              " 'world',\n",
              " 'bomb',\n",
              " 'fires',\n",
              " 'love',\n",
              " 'killed',\n",
              " 'go',\n",
              " 'attack',\n",
              " 'youtube',\n",
              " 'dead',\n",
              " 'two',\n",
              " 'families',\n",
              " '3',\n",
              " 'train',\n",
              " 'full',\n",
              " 'being',\n",
              " 'war',\n",
              " 'many',\n",
              " 'today',\n",
              " 'think',\n",
              " 'only',\n",
              " 'car',\n",
              " 'accident',\n",
              " 'life',\n",
              " 'hiroshima',\n",
              " 'their',\n",
              " 'say',\n",
              " 'may',\n",
              " 'down',\n",
              " 'watch',\n",
              " 'good',\n",
              " 'could',\n",
              " 'want',\n",
              " 'last',\n",
              " 'here',\n",
              " 'years',\n",
              " 'u',\n",
              " 'then',\n",
              " 'make',\n",
              " 'did',\n",
              " 'wildfire',\n",
              " 'way',\n",
              " 'help',\n",
              " 'best',\n",
              " 'too',\n",
              " 'even',\n",
              " 'because',\n",
              " 'home',\n",
              " 'death',\n",
              " 'collapse',\n",
              " 'bombing',\n",
              " 'mass',\n",
              " 'him',\n",
              " 'black',\n",
              " 'am',\n",
              " 'those',\n",
              " 'need',\n",
              " 'fatal',\n",
              " 'army',\n",
              " 'another',\n",
              " 'work',\n",
              " 'take',\n",
              " 'should',\n",
              " 'really',\n",
              " 'please',\n",
              " 'mh370',\n",
              " 'youre',\n",
              " 'look',\n",
              " 'lol',\n",
              " 'hot',\n",
              " 'pm',\n",
              " 'legionnaires',\n",
              " '4',\n",
              " 'right',\n",
              " '5',\n",
              " 'let',\n",
              " 'city',\n",
              " 'year',\n",
              " 'wreck',\n",
              " 'school',\n",
              " 'northern',\n",
              " 'much',\n",
              " 'forest',\n",
              " 'bomber',\n",
              " 'water',\n",
              " 'she',\n",
              " 'never',\n",
              " 'read',\n",
              " 'latest',\n",
              " 'homes',\n",
              " 'great',\n",
              " 'every',\n",
              " '1',\n",
              " 'live',\n",
              " 'god',\n",
              " 'fear',\n",
              " 'any',\n",
              " '\\x89√õ',\n",
              " 'under',\n",
              " 'said',\n",
              " 'old',\n",
              " 'floods',\n",
              " '2015',\n",
              " 'getting',\n",
              " 'atomic',\n",
              " 'while',\n",
              " 'top',\n",
              " 'obama',\n",
              " 'feel',\n",
              " 'thats',\n",
              " 'since',\n",
              " 'near',\n",
              " 'flames',\n",
              " 'ever',\n",
              " 'come',\n",
              " 'where',\n",
              " 'these',\n",
              " 'military',\n",
              " 'japan',\n",
              " 'found',\n",
              " 'content',\n",
              " 'ass',\n",
              " 'without',\n",
              " 'weather',\n",
              " 'most',\n",
              " 'flooding',\n",
              " 'flood',\n",
              " 'damage',\n",
              " 'which',\n",
              " 'shit',\n",
              " 's',\n",
              " 'hope',\n",
              " 'everyone',\n",
              " 'before',\n",
              " 'stop',\n",
              " 'plan',\n",
              " 'malaysia',\n",
              " 'injured',\n",
              " 'hit',\n",
              " 'evacuation',\n",
              " 'during',\n",
              " 'debris',\n",
              " 'cross',\n",
              " 'coming',\n",
              " 'wild',\n",
              " 'well',\n",
              " 'times',\n",
              " 'sinking',\n",
              " 'oil',\n",
              " 'fucking',\n",
              " 'check',\n",
              " 'cause',\n",
              " 'weapons',\n",
              " 'truck',\n",
              " 'food',\n",
              " 'bloody',\n",
              " 'always',\n",
              " 'weapon',\n",
              " 'theres',\n",
              " 'state',\n",
              " 'little',\n",
              " 'injuries',\n",
              " 'free',\n",
              " 'wounded',\n",
              " 'summer',\n",
              " 'smoke',\n",
              " 'severe',\n",
              " 'reddit',\n",
              " 'next',\n",
              " 'movie',\n",
              " 'ive',\n",
              " 'hes',\n",
              " 'fall',\n",
              " 'evacuate',\n",
              " 'confirmed',\n",
              " 'bad',\n",
              " 'again',\n",
              " 'thunderstorm',\n",
              " 'set',\n",
              " 'night',\n",
              " 'natural',\n",
              " 'looks',\n",
              " 'heat',\n",
              " 'face',\n",
              " 'earthquake',\n",
              " 'boy',\n",
              " 'whole',\n",
              " 'until',\n",
              " 'thunder',\n",
              " 'through',\n",
              " 'says',\n",
              " 'panic',\n",
              " 'outbreak',\n",
              " 'made',\n",
              " 'lightning',\n",
              " 'fatalities',\n",
              " 'family',\n",
              " 'explosion',\n",
              " 'end',\n",
              " 'destroy',\n",
              " 'derailment',\n",
              " 'air',\n",
              " 'w',\n",
              " 'terrorist',\n",
              " 'survive',\n",
              " 'screaming',\n",
              " 'saudi',\n",
              " 'refugees',\n",
              " 'rain',\n",
              " 'murder',\n",
              " 'loud',\n",
              " 'liked',\n",
              " 'house',\n",
              " 'gonna',\n",
              " 'failure',\n",
              " 'collided',\n",
              " 'bag',\n",
              " 'attacked',\n",
              " 'ambulance',\n",
              " '70',\n",
              " 'wind',\n",
              " 'services',\n",
              " 'save',\n",
              " 'report',\n",
              " 'migrants',\n",
              " 'head',\n",
              " 'explode',\n",
              " 'charged',\n",
              " 'change',\n",
              " 'big',\n",
              " 'also',\n",
              " 'wrecked',\n",
              " 'warning',\n",
              " 'update',\n",
              " 'run',\n",
              " 'rescuers',\n",
              " 'released',\n",
              " 'photo',\n",
              " 'massacre',\n",
              " 'injury',\n",
              " 'hurricane',\n",
              " 'high',\n",
              " 'hail',\n",
              " 'fuck',\n",
              " 'does',\n",
              " 'destroyed',\n",
              " 'bus',\n",
              " 'blood',\n",
              " '40',\n",
              " '\\x89√õ√í',\n",
              " 'wreckage',\n",
              " 'violent',\n",
              " 'twister',\n",
              " 'trauma',\n",
              " 'tragedy',\n",
              " 'terrorism',\n",
              " 'survivors',\n",
              " 'survived',\n",
              " 'sinkhole',\n",
              " 'sandstorm',\n",
              " 'road',\n",
              " 'rioting',\n",
              " 'red',\n",
              " 'real',\n",
              " 'put',\n",
              " 'post',\n",
              " 'national',\n",
              " 'missing',\n",
              " 'landslide',\n",
              " 'keep',\n",
              " 'girl',\n",
              " 'drought',\n",
              " 'curfew',\n",
              " 'breaking',\n",
              " 'bags',\n",
              " 'white',\n",
              " 'twitter',\n",
              " 'tonight',\n",
              " 'structural',\n",
              " 'spill',\n",
              " 'service',\n",
              " 'screamed',\n",
              " 'rescued',\n",
              " 'rescue',\n",
              " 'phone',\n",
              " 'ok',\n",
              " 'oh',\n",
              " 'mosque',\n",
              " 'lives',\n",
              " 'horrible',\n",
              " 'harm',\n",
              " 'game',\n",
              " 'dust',\n",
              " 'destruction',\n",
              " 'deluge',\n",
              " 'deaths',\n",
              " 'crashed',\n",
              " 'cliff',\n",
              " 'catastrophe',\n",
              " 'boat',\n",
              " 'away',\n",
              " 'august',\n",
              " 'area',\n",
              " 'apocalypse',\n",
              " 'woman',\n",
              " 'whirlwind',\n",
              " 'traumatised',\n",
              " 'stock',\n",
              " 'saw',\n",
              " 'ruin',\n",
              " 'riot',\n",
              " 'quarantine',\n",
              " 'kills',\n",
              " 'island',\n",
              " 'investigators',\n",
              " 'ill',\n",
              " 'hostages',\n",
              " 'hazard',\n",
              " 'danger',\n",
              " 'call',\n",
              " '15',\n",
              " 'women',\n",
              " 'windstorm',\n",
              " 'things',\n",
              " 'suspect',\n",
              " 'show',\n",
              " 'reunion',\n",
              " 'quarantined',\n",
              " 'lava',\n",
              " 'heart',\n",
              " 'engulfed',\n",
              " 'detonate',\n",
              " 'crush',\n",
              " 'collapsed',\n",
              " 'came',\n",
              " 'better',\n",
              " 'battle',\n",
              " 'armageddon',\n",
              " 'airplane',\n",
              " 'against',\n",
              " 'affected',\n",
              " 'use',\n",
              " 'trapped',\n",
              " 'thank',\n",
              " 'sunk',\n",
              " 'story',\n",
              " 'send',\n",
              " 'part',\n",
              " 'other',\n",
              " 'must',\n",
              " 'mudslide',\n",
              " 'market',\n",
              " 'iran',\n",
              " 'famine',\n",
              " 'exploded',\n",
              " 'electrocuted',\n",
              " 'ebay',\n",
              " 'displaced',\n",
              " 'derailed',\n",
              " 'derail',\n",
              " 'burned',\n",
              " 'bombed',\n",
              " 'blown',\n",
              " 'baby',\n",
              " 'around',\n",
              " 'zone',\n",
              " 'wave',\n",
              " 'wanna',\n",
              " 'sure',\n",
              " 'someone',\n",
              " 'screams',\n",
              " 'razed',\n",
              " 'power',\n",
              " 'obliterated',\n",
              " 'long',\n",
              " 'land',\n",
              " 'hundreds',\n",
              " 'heard',\n",
              " 'group',\n",
              " 'flattened',\n",
              " 'drown',\n",
              " 'doing',\n",
              " 'care',\n",
              " 'bridge',\n",
              " 'bagging',\n",
              " '9',\n",
              " 'went',\n",
              " 'used',\n",
              " 'typhoon',\n",
              " 'trouble',\n",
              " 'tornado',\n",
              " 'thought',\n",
              " 'thing',\n",
              " 'river',\n",
              " 'responders',\n",
              " 'past',\n",
              " 'pandemonium',\n",
              " 'officials',\n",
              " 'meltdown',\n",
              " 'lot',\n",
              " 'least',\n",
              " 'inundated',\n",
              " 'id',\n",
              " 'hostage',\n",
              " 'hijacking',\n",
              " 'hazardous',\n",
              " 'goes',\n",
              " 'drowning',\n",
              " 'didnt',\n",
              " 'devastation',\n",
              " 'demolish',\n",
              " 'collide',\n",
              " 'casualties',\n",
              " 'calgary',\n",
              " 'bang',\n",
              " 'anniversary',\n",
              " 'yet',\n",
              " 'wounds',\n",
              " 'volcano',\n",
              " 'tsunami',\n",
              " 'sue',\n",
              " 'st',\n",
              " 'song',\n",
              " 'something',\n",
              " 'shoulder',\n",
              " 'security',\n",
              " 'prebreak',\n",
              " 'possible',\n",
              " 'pkk',\n",
              " 'panicking',\n",
              " 'obliteration',\n",
              " 'obliterate',\n",
              " 'murderer',\n",
              " 'minute',\n",
              " 'light',\n",
              " 'lets',\n",
              " 'kill',\n",
              " 'isis',\n",
              " 'india',\n",
              " 'hijacker',\n",
              " 'hellfire',\n",
              " 'government',\n",
              " 'few',\n",
              " 'evacuated',\n",
              " 'due',\n",
              " 'detonated',\n",
              " 'desolation',\n",
              " 'crushed',\n",
              " 'chemical',\n",
              " 'blew',\n",
              " 'blazing',\n",
              " 'blast',\n",
              " 'annihilated',\n",
              " 'airport',\n",
              " '6',\n",
              " 'week',\n",
              " 'upheaval',\n",
              " 'trying',\n",
              " 'three',\n",
              " 'thanks',\n",
              " 'sound',\n",
              " 'soon',\n",
              " 'sirens',\n",
              " 'rainstorm',\n",
              " 'plane',\n",
              " 'music',\n",
              " 'making',\n",
              " 'kids',\n",
              " 'issues',\n",
              " 'half',\n",
              " 'guys',\n",
              " 'fedex',\n",
              " 'done',\n",
              " 'died',\n",
              " 'detonation',\n",
              " 'days',\n",
              " 'cyclone',\n",
              " 'county',\n",
              " 'collision',\n",
              " 'caused',\n",
              " 'catastrophic',\n",
              " 'bleeding',\n",
              " 'beautiful',\n",
              " '8',\n",
              " 'words',\n",
              " 'very',\n",
              " 'traffic',\n",
              " 'south',\n",
              " 'remember',\n",
              " 'policy',\n",
              " 'place',\n",
              " 'nothing',\n",
              " 'north',\n",
              " 'mp',\n",
              " 'longer',\n",
              " 'left',\n",
              " 'israeli',\n",
              " 'hell',\n",
              " 'fun',\n",
              " 'drowned',\n",
              " 'demolished',\n",
              " 'cool',\n",
              " 'both',\n",
              " 'bioterror',\n",
              " 'believe',\n",
              " 'avalanche',\n",
              " 'arson',\n",
              " 'turkey',\n",
              " 'snowstorm',\n",
              " 'site',\n",
              " 'shot',\n",
              " 'shooting',\n",
              " 'pic',\n",
              " 'nowplaying',\n",
              " 'media',\n",
              " 'islam',\n",
              " 'inside',\n",
              " 'hijack',\n",
              " 'helicopter',\n",
              " 'fight',\n",
              " 'fatality',\n",
              " 'fan',\n",
              " 'electrocute',\n",
              " 'doesnt',\n",
              " 'building',\n",
              " 'brown',\n",
              " 'bc',\n",
              " 'actually',\n",
              " '16yr',\n",
              " 'yes',\n",
              " 'watching',\n",
              " 'wait',\n",
              " 'ur',\n",
              " 'tell',\n",
              " 'swallowed',\n",
              " 'seismic',\n",
              " 'second',\n",
              " 'rubble',\n",
              " 're\\x89√õ',\n",
              " 'plans',\n",
              " 'men',\n",
              " 'memories',\n",
              " 'line',\n",
              " 'la',\n",
              " 'horror',\n",
              " 'health',\n",
              " 'having',\n",
              " 'find',\n",
              " 'eyewitness',\n",
              " 'deluged',\n",
              " 'children',\n",
              " 'bush',\n",
              " 'anything',\n",
              " 'already',\n",
              " 'almost',\n",
              " 'aircraft',\n",
              " 'yourself',\n",
              " 'yeah',\n",
              " 'whats',\n",
              " 'tomorrow',\n",
              " 'such',\n",
              " 'start',\n",
              " 'side',\n",
              " 'searching',\n",
              " 'saved',\n",
              " 'reactor',\n",
              " 'probably',\n",
              " 'play',\n",
              " 'person',\n",
              " 'peace',\n",
              " 'outside',\n",
              " 'officer',\n",
              " 'nearby',\n",
              " 'n',\n",
              " 'maybe',\n",
              " 'lost',\n",
              " 'literally',\n",
              " 'hours',\n",
              " 'hear',\n",
              " 'far',\n",
              " 'die',\n",
              " 'demolition',\n",
              " 'data',\n",
              " 'crews',\n",
              " 'conclusively',\n",
              " 'business',\n",
              " 'american',\n",
              " '20',\n",
              " '\\x89√õ√ì',\n",
              " 'west',\n",
              " 'waves',\n",
              " 'team',\n",
              " 'street',\n",
              " 'stay',\n",
              " 'soudelor',\n",
              " 'reuters',\n",
              " 'manslaughter',\n",
              " 'leather',\n",
              " 'job',\n",
              " 'history',\n",
              " 'hey',\n",
              " 'feeling',\n",
              " 'eyes',\n",
              " 'everything',\n",
              " 'declares',\n",
              " 'deal',\n",
              " 'casualty',\n",
              " 'bodies',\n",
              " 'amid',\n",
              " 'ablaze',\n",
              " '7',\n",
              " '50',\n",
              " '30',\n",
              " '12',\n",
              " 'youth',\n",
              " 'wont',\n",
              " 'wake',\n",
              " 'theyre',\n",
              " 'support',\n",
              " 'stretcher',\n",
              " 'same',\n",
              " 'rise',\n",
              " 'picking',\n",
              " 'photos',\n",
              " 'own',\n",
              " 'others',\n",
              " 'order',\n",
              " 'omg',\n",
              " 'okay',\n",
              " 'name',\n",
              " 'myself',\n",
              " 'money',\n",
              " 'makes',\n",
              " 'leave',\n",
              " 'lab',\n",
              " 'gt',\n",
              " 'gets',\n",
              " 'flag',\n",
              " 'desolate',\n",
              " 'crisis',\n",
              " 'center',\n",
              " 'book',\n",
              " 'blight',\n",
              " 'blaze',\n",
              " 'ago',\n",
              " 'abc',\n",
              " '11yearold',\n",
              " 'womens',\n",
              " 'typhoondevastated',\n",
              " 'tv',\n",
              " 'trench',\n",
              " 'trains',\n",
              " 'texas',\n",
              " 'space',\n",
              " 'siren',\n",
              " 'shes',\n",
              " 'self',\n",
              " 'saipan',\n",
              " 'reason',\n",
              " 'rd',\n",
              " 'pretty',\n",
              " 'pick',\n",
              " 'offensive',\n",
              " 'move',\n",
              " 'meek',\n",
              " 'major',\n",
              " 'm',\n",
              " 'low',\n",
              " 'lord',\n",
              " 'huge',\n",
              " 'hat',\n",
              " 'flash',\n",
              " 'feared',\n",
              " 'fast',\n",
              " 'effect',\n",
              " 'course',\n",
              " 'country',\n",
              " 'control',\n",
              " 'class',\n",
              " 'child',\n",
              " 'chance',\n",
              " 'caught',\n",
              " 'called',\n",
              " 'bioterrorism',\n",
              " 'bestnaijamade',\n",
              " 'become',\n",
              " 'bar',\n",
              " 'banned',\n",
              " 'ball',\n",
              " 'aug',\n",
              " 'annihilation',\n",
              " 'wrong',\n",
              " 'win',\n",
              " 'usa',\n",
              " 'united',\n",
              " 'town',\n",
              " 'totally',\n",
              " 'toddler',\n",
              " 'though',\n",
              " 'temple',\n",
              " 'taken',\n",
              " 'stand',\n",
              " 'spot',\n",
              " 'signs',\n",
              " 'ship',\n",
              " 'pakistan',\n",
              " 'online',\n",
              " 'level',\n",
              " 'ladies',\n",
              " 'jobs',\n",
              " 'isnt',\n",
              " 'happy',\n",
              " 'hailstorm',\n",
              " 'friends',\n",
              " 'disea',\n",
              " 'damn',\n",
              " 'couple',\n",
              " 'case',\n",
              " 'blue',\n",
              " 'bigger',\n",
              " 'america',\n",
              " 'across',\n",
              " '10',\n",
              " 'yours',\n",
              " 'village',\n",
              " 'try',\n",
              " 'transport',\n",
              " 'talk',\n",
              " 'seen',\n",
              " 'russian',\n",
              " 'radio',\n",
              " 'projected',\n",
              " 'once',\n",
              " 'official',\n",
              " 'needs',\n",
              " 'nearly',\n",
              " 'mount',\n",
              " 'might',\n",
              " 'mayhem',\n",
              " 'instead',\n",
              " 'hollywood',\n",
              " 'haha',\n",
              " 'guy',\n",
              " 'gun',\n",
              " 'green',\n",
              " 'front',\n",
              " 'finally',\n",
              " 'favorite',\n",
              " 'experts',\n",
              " 'entire',\n",
              " 'east',\n",
              " 'daily',\n",
              " 'crazy',\n",
              " 'computers',\n",
              " 'coaches',\n",
              " 'christian',\n",
              " 'china',\n",
              " 'blizzard',\n",
              " 'anyone',\n",
              " 'aint',\n",
              " 'action',\n",
              " '25',\n",
              " 'virgin',\n",
              " 'vehicle',\n",
              " 'truth',\n",
              " 'trust',\n",
              " 'takes',\n",
              " 't',\n",
              " 'star',\n",
              " 'sorry',\n",
              " 'running',\n",
              " 'refugio',\n",
              " 'reddits',\n",
              " 'poor',\n",
              " 'pain',\n",
              " 'mom',\n",
              " 'miners',\n",
              " 'marks',\n",
              " 'looking',\n",
              " 'knock',\n",
              " 'issued',\n",
              " 'insurance',\n",
              " 'ignition',\n",
              " 'houses',\n",
              " 'heavy',\n",
              " 'hate',\n",
              " 'hard',\n",
              " 'happened',\n",
              " 'global',\n",
              " 'giant',\n",
              " 'gbbo',\n",
              " 'flight',\n",
              " 'eye',\n",
              " 'emmerdale',\n",
              " 'driver',\n",
              " 'devastated',\n",
              " 'd',\n",
              " 'costlier',\n",
              " 'cnn',\n",
              " 'cars',\n",
              " 'camp',\n",
              " 'beach',\n",
              " 'arsonist',\n",
              " 'angry',\n",
              " 'alone',\n",
              " 'added',\n",
              " '05',\n",
              " 'york',\n",
              " 'wonder',\n",
              " 'uk',\n",
              " 'turn',\n",
              " 'taking',\n",
              " 'subreddits',\n",
              " 'sounds',\n",
              " 'scared',\n",
              " 'russia',\n",
              " 'rly',\n",
              " 'reports',\n",
              " 'ready',\n",
              " 'quiz',\n",
              " 'public',\n",
              " 'property',\n",
              " 'pradesh',\n",
              " 'ppl',\n",
              " 'playing',\n",
              " 'pay',\n",
              " 'parole',\n",
              " 'pamela',\n",
              " 'pakistani',\n",
              " 'outrage',\n",
              " 'niggas',\n",
              " 'nagasaki',\n",
              " 'myanmar',\n",
              " 'muslims',\n",
              " 'mop',\n",
              " 'madhya',\n",
              " 'mad',\n",
              " 'lmao',\n",
              " 'learn',\n",
              " 'large',\n",
              " 'govt',\n",
              " 'give',\n",
              " 'gems',\n",
              " 'gave',\n",
              " 'funtenna',\n",
              " 'fukushima',\n",
              " 'former',\n",
              " 'film',\n",
              " 'earth',\n",
              " 'drive',\n",
              " 'downtown',\n",
              " 'dog',\n",
              " 'comes',\n",
              " 'closed',\n",
              " 'cake',\n",
              " 'british',\n",
              " 'bring',\n",
              " 'bbc',\n",
              " 'b',\n",
              " 'appears',\n",
              " 'aftershock',\n",
              " '13',\n",
              " '11',\n",
              " 'young',\n",
              " 'wow',\n",
              " 'worst',\n",
              " 'waving',\n",
              " 'washington',\n",
              " 'wanted',\n",
              " 'vs',\n",
              " 'view',\n",
              " 'upon',\n",
              " 'tweet',\n",
              " 'tree',\n",
              " 'tote',\n",
              " 'thousands',\n",
              " 'thinking',\n",
              " 'theater',\n",
              " 'soul',\n",
              " 'sky',\n",
              " 'sign',\n",
              " 'shows',\n",
              " 'shift',\n",
              " 'seeing',\n",
              " 'sea',\n",
              " 'scene',\n",
              " 'safety',\n",
              " 'rules',\n",
              " 'rock',\n",
              " 'reported',\n",
              " 'r',\n",
              " 'pray',\n",
              " 'playlist',\n",
              " 'patience',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tRsb6FiDsoZ",
        "outputId": "749ea78e-d8f4-4fec-f140-d37c131ebbff"
      },
      "source": [
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E18a1lm4Dz-T",
        "outputId": "085ac49d-2a52-4d5c-981f-bb8d065e39b5"
      },
      "source": [
        "#model 1 summary\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax6ISou9D5Ec",
        "outputId": "e49626de-0d39-447c-ac43-d94256c8bec3"
      },
      "source": [
        "#get the weight matrix of embedding layer\n",
        "embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "embed_weights.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1pEz0EREZpF"
      },
      "source": [
        "import io\n",
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iw9w1m4FlFx"
      },
      "source": [
        "## Recurrent Neural Networks(RNN's)\n",
        "\n",
        "its useful for sequence data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADXfpfF8ItDp"
      },
      "source": [
        "###Model 2:LSTM\n",
        "\n",
        "LSTM = long short term memory(one fo the most popular)\n",
        "\n",
        "input->tokenize->embedding>layers(RNNs/dense)->output(label probability)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCSulLYzJTox",
        "outputId": "f4685da2-447b-4bf4-b8f1-de4bdf0f9af3"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype = \"string\")\n",
        "x= text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(64, return_sequences=True)(x)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "print(x.shape)\n",
        "x = layers.Dense(64,activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs,outputs,name=\"model_2_LSTM\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 64)\n",
            "(None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTCUTNiMKYx0"
      },
      "source": [
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KuCyzH0OyXS",
        "outputId": "7dc95687-17a3-4cb3-8983-8c12ca56ac1a"
      },
      "source": [
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(save_dir,\n",
        "                                                                    \"model_2_LSTM\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20210815-121757\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 24ms/step - loss: 0.2207 - accuracy: 0.9226 - val_loss: 0.5359 - val_accuracy: 0.7848\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.1599 - accuracy: 0.9406 - val_loss: 0.6977 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.1303 - accuracy: 0.9511 - val_loss: 0.6789 - val_accuracy: 0.7782\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.1050 - accuracy: 0.9580 - val_loss: 0.8261 - val_accuracy: 0.7769\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.0849 - accuracy: 0.9672 - val_loss: 1.0760 - val_accuracy: 0.7782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wR8sq6IPDPF",
        "outputId": "e9755888-6c81-4a48-9fc1-c7341c46b35a"
      },
      "source": [
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[-10:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9998593e-01],\n",
              "       [3.0501635e-04],\n",
              "       [9.9996173e-01],\n",
              "       [9.9508190e-01],\n",
              "       [2.6249707e-02],\n",
              "       [5.5162199e-02],\n",
              "       [4.0311202e-02],\n",
              "       [8.6547726e-01],\n",
              "       [1.9815534e-02],\n",
              "       [1.1758953e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuCvJ80XQFAP"
      },
      "source": [
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rnMF4hgQNfa"
      },
      "source": [
        "model_2_results = calculate_results(val_labels,\n",
        "                                    model_2_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7Yio_FoQSav",
        "outputId": "261ad2f4-a519-4bf4-f9ac-40e43a7259dc"
      },
      "source": [
        "model_2_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7782152230971129,\n",
              " 'f1': array([0.80462428, 0.74355083]),\n",
              " 'precision': array([0.77161863, 0.78778135]),\n",
              " 'recall': array([0.84057971, 0.70402299])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNaW4oRdQTxS",
        "outputId": "c16b6747-a06f-4544-b6f2-3f008d6b598c"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7926509186351706,\n",
              " 'f1': array([0.83010753, 0.73400673]),\n",
              " 'precision': array([0.74806202, 0.88617886]),\n",
              " 'recall': array([0.93236715, 0.62643678])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PnXhCYpQYRA"
      },
      "source": [
        "###Model 3 :GRU\n",
        "\n",
        "Another popular and effective RNN component is gru or gated recurrent network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXzR_xLZQ-KH",
        "outputId": "71163f82-d379-4e11-9368-0d177de6a5c7"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype = \"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "x = layers.GRU(64,return_sequences=True)(x)\n",
        "print(x.shape)\n",
        "x = layers.LSTM(64,return_sequences=True)(x)\n",
        "print(x.shape)\n",
        "x = layers.GRU(64)(x)\n",
        "print(x.shape)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs,outputs,name=\"model_3_GRU\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 64)\n",
            "(None, 15, 64)\n",
            "(None, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMXudvXKTZx5",
        "outputId": "9310a525-7e49-4805-b059-46252a8f2f83"
      },
      "source": [
        "model_3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 15, 64)            37248     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 15, 64)            33024     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 64)                24960     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,379,457\n",
            "Trainable params: 1,379,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T57vbg7gSCke"
      },
      "source": [
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bZBra0HSLNx",
        "outputId": "482f8c2a-89e3-4347-903d-a2a564dd3b73"
      },
      "source": [
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences,val_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 23ms/step - loss: 0.1416 - accuracy: 0.9518 - val_loss: 0.9233 - val_accuracy: 0.7690\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.0755 - accuracy: 0.9699 - val_loss: 0.8869 - val_accuracy: 0.7808\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.0618 - accuracy: 0.9730 - val_loss: 1.1575 - val_accuracy: 0.7717\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.0578 - accuracy: 0.9747 - val_loss: 1.3995 - val_accuracy: 0.7703\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 19ms/step - loss: 0.0596 - accuracy: 0.9736 - val_loss: 1.2494 - val_accuracy: 0.7717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktRaBgN0SZar",
        "outputId": "bc0c86fd-03ce-4c39-a876-8707f32e3fc2"
      },
      "source": [
        "model_3_history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff7a35a0e90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIb0_3-kUOMC"
      },
      "source": [
        "###Model 4: Bidirectional RNN\n",
        "\n",
        "normal rnn goes from left to right but bidirectional (as the name sya enough) it goes left to right as well as right to left"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARZ8qa2BWMHL"
      },
      "source": [
        "# building it \n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,),dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.GRU(64,return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.GRU(64))(x)\n",
        "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs,outputs,name=\"model_4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsJJon8HXA3c"
      },
      "source": [
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FynFPdo2XMvE",
        "outputId": "f042a718-2c0c-4714-f715-d4647e39dbd3"
      },
      "source": [
        "model_4.fit(train_sentences,\n",
        "            train_labels,\n",
        "            epochs=5,\n",
        "            validation_data=(val_sentences,val_labels),\n",
        "            callbacks=[create_tensorboard_callback(save_dir,\n",
        "                                                   \"model_4\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4/20210815-121850\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 31ms/step - loss: 0.1138 - accuracy: 0.9610 - val_loss: 0.7635 - val_accuracy: 0.7730\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.0670 - accuracy: 0.9737 - val_loss: 1.0365 - val_accuracy: 0.7782\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 21ms/step - loss: 0.0495 - accuracy: 0.9780 - val_loss: 1.3188 - val_accuracy: 0.7690\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.0504 - accuracy: 0.9766 - val_loss: 1.3604 - val_accuracy: 0.7638\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.0412 - accuracy: 0.9794 - val_loss: 1.4549 - val_accuracy: 0.7493\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff7a0b750d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KzKgGp3XYcp"
      },
      "source": [
        "model_4_pred_probs = model_4.predict(val_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkz2RkOrXlUZ"
      },
      "source": [
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZRh7QGtXpvz"
      },
      "source": [
        "model_4_results = calculate_results(val_labels,\n",
        "                                    model_4_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2KSbmU1XwKS",
        "outputId": "169b6403-85b2-406a-a8d2-cbbd1a3bd9ac"
      },
      "source": [
        "model_4_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7493438320209974,\n",
              " 'f1': array([0.77070828, 0.723589  ]),\n",
              " 'precision': array([0.76610979, 0.72886297]),\n",
              " 'recall': array([0.77536232, 0.7183908 ])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x3tVDVgXxt-"
      },
      "source": [
        "###Model 4: 1D CNN convolution neural network\n",
        "\n",
        "before we used it to play with images which is basically 2D but here we will use use Conv1D because our text is 1D\n",
        "\n",
        "input->tokenization->embedding->layer(con1d+pooling)->outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOBDlVw3YlcF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d1100a-ad2a-479e-cc80-7f8a223b3586"
      },
      "source": [
        "embedding_test = embedding(text_vectorizer([\"this is lola lallan\"]))\n",
        "conv_1d = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5,\n",
        "                        activation=\"relu\",\n",
        "                        padding=\"valid\")\n",
        "conv_1d_output = conv_1d(embedding_test)#passing the test embedding through the conv1D lyer\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output)# get the  feature with the highest value\n",
        "\n",
        "embedding_test.shape,conv_1d_output.shape, max_pool_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlLYijxRNTYC",
        "outputId": "7ea55454-a8d8-443c-a4b4-a762435e287d"
      },
      "source": [
        "inputs = layers.Input(shape=(1,),dtype=tf.string)\n",
        "\n",
        "x = embedding(text_vectorizer(inputs))\n",
        "\n",
        "x = layers.Conv1D(filters=64,\n",
        "                  kernel_size = 5,\n",
        "                  strides=1,\n",
        "                  activation=\"relu\",\n",
        "                  padding=\"valid\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "\n",
        "outputs = layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "\n",
        "model_5 = tf.keras.Model(inputs,outputs,name=\"model_5_conv1D\")\n",
        "\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "model_5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5_conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,321,089\n",
            "Trainable params: 1,321,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgAf7I46P8PO",
        "outputId": "725f65c7-0633-4292-b332-c4c9afe3f12a"
      },
      "source": [
        "model_5.history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data = (val_sentences,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(save_dir,\n",
        "                                                                     \"model_5\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_5/20210815-121945\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 6s 18ms/step - loss: 0.1287 - accuracy: 0.9591 - val_loss: 0.8527 - val_accuracy: 0.7690\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0746 - accuracy: 0.9714 - val_loss: 1.0268 - val_accuracy: 0.7638\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0606 - accuracy: 0.9759 - val_loss: 1.1278 - val_accuracy: 0.7664\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0551 - accuracy: 0.9774 - val_loss: 1.1965 - val_accuracy: 0.7677\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0507 - accuracy: 0.9777 - val_loss: 1.1998 - val_accuracy: 0.7598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWjrioikQnKp",
        "outputId": "6e9f4a0f-498e-4c74-e445-36f058f3eefd"
      },
      "source": [
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.79487187e-01],\n",
              "       [9.54686165e-01],\n",
              "       [9.99829054e-01],\n",
              "       [2.81389002e-02],\n",
              "       [1.00381226e-06],\n",
              "       [9.89360452e-01],\n",
              "       [8.75649273e-01],\n",
              "       [9.99954224e-01],\n",
              "       [9.99999404e-01],\n",
              "       [6.15010798e-01],\n",
              "       [2.86678755e-07],\n",
              "       [8.69943082e-01],\n",
              "       [1.02815093e-05],\n",
              "       [2.29316711e-01],\n",
              "       [1.33221715e-06],\n",
              "       [2.00079996e-02],\n",
              "       [1.30555069e-03],\n",
              "       [9.81802714e-06],\n",
              "       [6.35905005e-03],\n",
              "       [9.99382377e-01],\n",
              "       [8.79668832e-01],\n",
              "       [1.37395068e-06],\n",
              "       [9.99822676e-01],\n",
              "       [6.71723625e-04],\n",
              "       [9.99988556e-01],\n",
              "       [1.00000000e+00],\n",
              "       [1.29212349e-04],\n",
              "       [2.87840609e-04],\n",
              "       [9.83760328e-05],\n",
              "       [5.71585476e-01],\n",
              "       [3.17132026e-01],\n",
              "       [4.24876052e-05],\n",
              "       [1.91149697e-01],\n",
              "       [4.14095633e-03],\n",
              "       [3.45243476e-02],\n",
              "       [6.95243895e-01],\n",
              "       [9.99998927e-01],\n",
              "       [9.98291746e-02],\n",
              "       [9.05097369e-03],\n",
              "       [9.98899698e-01],\n",
              "       [4.22520161e-01],\n",
              "       [9.12655232e-05],\n",
              "       [1.20356955e-01],\n",
              "       [1.34887901e-04],\n",
              "       [9.91237640e-01],\n",
              "       [9.99989986e-01],\n",
              "       [9.88738656e-01],\n",
              "       [9.99669671e-01],\n",
              "       [3.16856243e-03],\n",
              "       [5.18873930e-01],\n",
              "       [5.53736390e-05],\n",
              "       [2.94711590e-01],\n",
              "       [3.15078162e-03],\n",
              "       [4.85586748e-02],\n",
              "       [8.75788510e-01],\n",
              "       [2.87144594e-02],\n",
              "       [9.76139959e-03],\n",
              "       [9.99997377e-01],\n",
              "       [3.25275614e-05],\n",
              "       [2.13400895e-07],\n",
              "       [1.64861809e-02],\n",
              "       [9.99999285e-01],\n",
              "       [9.92106318e-01],\n",
              "       [5.77282719e-03],\n",
              "       [9.96775687e-01],\n",
              "       [9.99995828e-01],\n",
              "       [9.90872085e-01],\n",
              "       [3.38278071e-04],\n",
              "       [9.56391037e-01],\n",
              "       [5.83584644e-02],\n",
              "       [2.63790775e-04],\n",
              "       [5.56738488e-02],\n",
              "       [9.98414516e-01],\n",
              "       [3.75607610e-03],\n",
              "       [9.84404266e-01],\n",
              "       [9.74707425e-01],\n",
              "       [6.49403548e-03],\n",
              "       [9.81741369e-01],\n",
              "       [4.68285501e-01],\n",
              "       [2.32459992e-04],\n",
              "       [4.06349629e-01],\n",
              "       [4.32687365e-02],\n",
              "       [1.00000000e+00],\n",
              "       [2.65854876e-04],\n",
              "       [1.43099735e-02],\n",
              "       [5.78614592e-04],\n",
              "       [2.42870119e-05],\n",
              "       [7.31702289e-03],\n",
              "       [3.37442040e-01],\n",
              "       [9.99996424e-01],\n",
              "       [9.99999881e-01],\n",
              "       [4.12177433e-05],\n",
              "       [9.29626644e-01],\n",
              "       [1.84419099e-02],\n",
              "       [9.99999881e-01],\n",
              "       [9.54686165e-01],\n",
              "       [9.80535328e-01],\n",
              "       [9.95372951e-01],\n",
              "       [9.98949230e-01],\n",
              "       [9.97371554e-01],\n",
              "       [1.00000000e+00],\n",
              "       [4.44523990e-04],\n",
              "       [1.38865437e-06],\n",
              "       [9.31172669e-01],\n",
              "       [9.98365700e-01],\n",
              "       [9.13411528e-02],\n",
              "       [9.99526024e-01],\n",
              "       [9.99972224e-01],\n",
              "       [1.62523122e-07],\n",
              "       [9.98602211e-01],\n",
              "       [8.60533774e-01],\n",
              "       [2.85556712e-06],\n",
              "       [9.81569439e-02],\n",
              "       [1.07085070e-04],\n",
              "       [2.92363996e-03],\n",
              "       [3.78900141e-01],\n",
              "       [4.14088070e-01],\n",
              "       [9.99331653e-01],\n",
              "       [3.47936243e-01],\n",
              "       [3.83527920e-04],\n",
              "       [1.00000000e+00],\n",
              "       [8.27199801e-06],\n",
              "       [1.93151068e-02],\n",
              "       [8.61620128e-01],\n",
              "       [8.19262326e-01],\n",
              "       [5.77811478e-03],\n",
              "       [9.92304146e-01],\n",
              "       [3.68229121e-05],\n",
              "       [3.22945329e-04],\n",
              "       [9.97375607e-01],\n",
              "       [3.49378206e-05],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [9.99941945e-01],\n",
              "       [4.43891734e-02],\n",
              "       [9.99986172e-01],\n",
              "       [7.45488703e-01],\n",
              "       [6.54254749e-04],\n",
              "       [7.05775747e-04],\n",
              "       [1.00000000e+00],\n",
              "       [9.04163361e-01],\n",
              "       [2.29316711e-01],\n",
              "       [9.99951482e-01],\n",
              "       [5.18205911e-02],\n",
              "       [3.74884829e-02],\n",
              "       [4.06558998e-02],\n",
              "       [6.95739188e-10],\n",
              "       [1.18398899e-03],\n",
              "       [7.48319864e-01],\n",
              "       [2.15143641e-03],\n",
              "       [1.97191332e-02],\n",
              "       [3.11571527e-02],\n",
              "       [1.87930937e-09],\n",
              "       [1.38418972e-02],\n",
              "       [9.99989629e-01],\n",
              "       [9.99584138e-01],\n",
              "       [1.05823157e-02],\n",
              "       [9.89157677e-01],\n",
              "       [3.80078866e-08],\n",
              "       [7.62587368e-01],\n",
              "       [1.74198449e-01],\n",
              "       [2.17046380e-01],\n",
              "       [9.99994159e-01],\n",
              "       [7.02703744e-03],\n",
              "       [2.84148176e-04],\n",
              "       [1.00000000e+00],\n",
              "       [1.79188564e-01],\n",
              "       [9.99987483e-01],\n",
              "       [4.60446358e-01],\n",
              "       [9.99989390e-01],\n",
              "       [9.99350250e-01],\n",
              "       [9.98819053e-01],\n",
              "       [1.07937340e-05],\n",
              "       [9.99998093e-01],\n",
              "       [1.20894006e-03],\n",
              "       [1.24879062e-01],\n",
              "       [5.26800901e-02],\n",
              "       [9.57347035e-01],\n",
              "       [9.99989629e-01],\n",
              "       [2.06246987e-04],\n",
              "       [9.94790196e-01],\n",
              "       [9.98766541e-01],\n",
              "       [9.99999762e-01],\n",
              "       [9.90075529e-01],\n",
              "       [1.01233041e-03],\n",
              "       [4.36422351e-06],\n",
              "       [1.00000000e+00],\n",
              "       [3.15991770e-07],\n",
              "       [7.68408537e-09],\n",
              "       [4.06499170e-02],\n",
              "       [1.90315023e-01],\n",
              "       [1.42104327e-05],\n",
              "       [1.30209621e-04],\n",
              "       [5.79788804e-08],\n",
              "       [5.04406926e-05],\n",
              "       [1.52684312e-04],\n",
              "       [2.34636199e-02],\n",
              "       [9.99359429e-01],\n",
              "       [1.78380636e-04],\n",
              "       [1.42845791e-03],\n",
              "       [9.99543726e-01],\n",
              "       [9.99879956e-01],\n",
              "       [6.49123034e-03],\n",
              "       [1.56049602e-04],\n",
              "       [1.00000000e+00],\n",
              "       [9.99972224e-01],\n",
              "       [9.99993324e-01],\n",
              "       [8.73180091e-01],\n",
              "       [9.88729000e-01],\n",
              "       [4.44814354e-01],\n",
              "       [1.00000000e+00],\n",
              "       [2.47201183e-06],\n",
              "       [5.26415315e-05],\n",
              "       [7.87548444e-08],\n",
              "       [9.02351616e-09],\n",
              "       [9.99844193e-01],\n",
              "       [9.95554984e-01],\n",
              "       [9.92155790e-01],\n",
              "       [9.51466143e-01],\n",
              "       [1.26583338e-01],\n",
              "       [1.50422609e-04],\n",
              "       [1.72997432e-04],\n",
              "       [3.62948369e-04],\n",
              "       [9.99997735e-01],\n",
              "       [5.93117356e-01],\n",
              "       [9.39415470e-02],\n",
              "       [1.00000000e+00],\n",
              "       [9.53492522e-01],\n",
              "       [8.99508953e-01],\n",
              "       [1.05191499e-03],\n",
              "       [1.74642857e-02],\n",
              "       [9.93630588e-01],\n",
              "       [1.95407793e-01],\n",
              "       [3.55228513e-01],\n",
              "       [4.58261929e-03],\n",
              "       [3.37332159e-01],\n",
              "       [1.09239355e-01],\n",
              "       [1.26940031e-02],\n",
              "       [2.59021908e-04],\n",
              "       [5.85471094e-01],\n",
              "       [5.14977016e-02],\n",
              "       [1.00000000e+00],\n",
              "       [9.99963522e-01],\n",
              "       [1.81069001e-04],\n",
              "       [2.64081194e-07],\n",
              "       [9.99999285e-01],\n",
              "       [6.04798661e-05],\n",
              "       [3.27605917e-03],\n",
              "       [2.27175102e-01],\n",
              "       [2.39205679e-06],\n",
              "       [9.96644139e-01],\n",
              "       [2.55747090e-10],\n",
              "       [5.87650611e-05],\n",
              "       [9.99973536e-01],\n",
              "       [1.13431700e-01],\n",
              "       [9.99534011e-01],\n",
              "       [1.00000000e+00],\n",
              "       [2.55607255e-03],\n",
              "       [6.17994694e-04],\n",
              "       [1.11064268e-02],\n",
              "       [2.42319002e-04],\n",
              "       [8.93140452e-07],\n",
              "       [9.99999762e-01],\n",
              "       [9.99966621e-01],\n",
              "       [6.03033304e-01],\n",
              "       [9.99976635e-01],\n",
              "       [9.63655984e-05],\n",
              "       [7.37009272e-02],\n",
              "       [2.00477876e-02],\n",
              "       [7.51096476e-03],\n",
              "       [2.33029259e-05],\n",
              "       [9.99999404e-01],\n",
              "       [3.29392171e-03],\n",
              "       [1.71585796e-07],\n",
              "       [9.99999285e-01],\n",
              "       [7.18060110e-05],\n",
              "       [2.28538731e-04],\n",
              "       [9.99411345e-01],\n",
              "       [3.22491505e-05],\n",
              "       [5.84367430e-03],\n",
              "       [1.18243370e-04],\n",
              "       [9.99993205e-01],\n",
              "       [9.98214245e-01],\n",
              "       [7.23496974e-01],\n",
              "       [1.56013265e-01],\n",
              "       [9.99818265e-01],\n",
              "       [2.05860450e-03],\n",
              "       [9.99758542e-01],\n",
              "       [3.07089795e-04],\n",
              "       [4.92982894e-01],\n",
              "       [9.99806225e-01],\n",
              "       [5.58247626e-01],\n",
              "       [2.01708347e-01],\n",
              "       [3.28135066e-04],\n",
              "       [9.44991052e-01],\n",
              "       [3.37952934e-03],\n",
              "       [4.89575267e-02],\n",
              "       [3.64019885e-03],\n",
              "       [2.50857681e-01],\n",
              "       [2.72824150e-06],\n",
              "       [1.95507589e-03],\n",
              "       [7.66399726e-02],\n",
              "       [9.99976516e-01],\n",
              "       [2.86555453e-03],\n",
              "       [2.58390704e-04],\n",
              "       [8.01457167e-01],\n",
              "       [1.53118357e-01],\n",
              "       [1.58538409e-02],\n",
              "       [2.15607670e-05],\n",
              "       [1.67194885e-04],\n",
              "       [9.99960065e-01],\n",
              "       [4.43200856e-01],\n",
              "       [3.53786439e-01],\n",
              "       [1.00000000e+00],\n",
              "       [5.65717928e-04],\n",
              "       [9.99029279e-01],\n",
              "       [1.59335360e-01],\n",
              "       [1.65552301e-05],\n",
              "       [5.67165241e-02],\n",
              "       [3.00298052e-06],\n",
              "       [1.23792598e-02],\n",
              "       [9.99965668e-01],\n",
              "       [1.61269322e-01],\n",
              "       [9.99999881e-01],\n",
              "       [5.18312752e-02],\n",
              "       [2.99988028e-06],\n",
              "       [9.99997854e-01],\n",
              "       [1.47343220e-04],\n",
              "       [9.99999881e-01],\n",
              "       [1.06613028e-04],\n",
              "       [1.28667298e-05],\n",
              "       [1.00000000e+00],\n",
              "       [9.71721147e-06],\n",
              "       [4.64857612e-06],\n",
              "       [9.99968410e-01],\n",
              "       [8.64882713e-06],\n",
              "       [2.18071564e-05],\n",
              "       [9.99756038e-01],\n",
              "       [9.99628067e-01],\n",
              "       [1.15477917e-06],\n",
              "       [2.76263785e-02],\n",
              "       [9.99997854e-01],\n",
              "       [9.82574940e-01],\n",
              "       [9.98008311e-01],\n",
              "       [6.20378703e-02],\n",
              "       [8.70889664e-01],\n",
              "       [9.99081254e-01],\n",
              "       [2.99276784e-03],\n",
              "       [3.42522922e-04],\n",
              "       [6.21286640e-03],\n",
              "       [1.12263067e-02],\n",
              "       [3.08650260e-06],\n",
              "       [8.21577191e-01],\n",
              "       [1.65291891e-01],\n",
              "       [1.30529168e-06],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [4.58039867e-05],\n",
              "       [1.24305673e-01],\n",
              "       [1.93781052e-02],\n",
              "       [3.13424498e-01],\n",
              "       [9.91647601e-01],\n",
              "       [9.89097953e-02],\n",
              "       [1.13881344e-03],\n",
              "       [5.35652191e-07],\n",
              "       [2.24447884e-02],\n",
              "       [9.93752778e-01],\n",
              "       [3.33706703e-04],\n",
              "       [7.95943104e-03],\n",
              "       [3.40834254e-06],\n",
              "       [4.79327142e-03],\n",
              "       [1.09611377e-01],\n",
              "       [9.93629634e-01],\n",
              "       [2.23036427e-02],\n",
              "       [1.19783881e-05],\n",
              "       [2.49766256e-03],\n",
              "       [1.56496353e-02],\n",
              "       [1.00000000e+00],\n",
              "       [9.98682082e-01],\n",
              "       [7.60926545e-01],\n",
              "       [9.95687783e-01],\n",
              "       [6.21837204e-09],\n",
              "       [7.78227091e-01],\n",
              "       [9.99999642e-01],\n",
              "       [7.90290594e-01],\n",
              "       [7.53607824e-02],\n",
              "       [9.99995232e-01],\n",
              "       [3.78030762e-02],\n",
              "       [9.99943852e-01],\n",
              "       [7.77849171e-04],\n",
              "       [1.33365244e-02],\n",
              "       [7.85976768e-01],\n",
              "       [7.55203441e-02],\n",
              "       [1.00000000e+00],\n",
              "       [1.79320853e-02],\n",
              "       [1.23942264e-05],\n",
              "       [8.01285714e-05],\n",
              "       [9.89097953e-02],\n",
              "       [1.00000000e+00],\n",
              "       [2.85750830e-05],\n",
              "       [2.91129649e-02],\n",
              "       [9.99968529e-01],\n",
              "       [4.95176355e-04],\n",
              "       [1.00000000e+00],\n",
              "       [2.13392768e-02],\n",
              "       [1.78469098e-04],\n",
              "       [8.38229619e-03],\n",
              "       [9.99466956e-01],\n",
              "       [9.98538613e-01],\n",
              "       [2.23691095e-04],\n",
              "       [1.70463977e-06],\n",
              "       [1.48362592e-01],\n",
              "       [9.99996185e-01],\n",
              "       [3.71002883e-01],\n",
              "       [4.53008834e-04],\n",
              "       [1.29885748e-01],\n",
              "       [2.19026849e-01],\n",
              "       [1.05371764e-05],\n",
              "       [9.99999166e-01],\n",
              "       [7.14216053e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.99924302e-01],\n",
              "       [9.04487669e-02],\n",
              "       [9.79414999e-01],\n",
              "       [1.78144197e-04],\n",
              "       [9.99417782e-01],\n",
              "       [9.99635100e-01],\n",
              "       [9.99573410e-01],\n",
              "       [9.10838949e-04],\n",
              "       [5.06172888e-02],\n",
              "       [1.87337118e-05],\n",
              "       [2.98097701e-04],\n",
              "       [2.07474068e-06],\n",
              "       [1.33188372e-03],\n",
              "       [8.30869913e-01],\n",
              "       [3.93438293e-03],\n",
              "       [1.00000000e+00],\n",
              "       [9.99977589e-01],\n",
              "       [2.04460844e-01],\n",
              "       [9.54686165e-01],\n",
              "       [5.06621692e-03],\n",
              "       [6.41443621e-05],\n",
              "       [1.89484403e-01],\n",
              "       [5.93412697e-01],\n",
              "       [6.63760081e-02],\n",
              "       [5.46505600e-02],\n",
              "       [7.16974273e-06],\n",
              "       [2.07677644e-04],\n",
              "       [1.05278339e-07],\n",
              "       [9.99758661e-01],\n",
              "       [9.99337614e-01],\n",
              "       [9.99996781e-01],\n",
              "       [2.57456422e-01],\n",
              "       [8.66332471e-01],\n",
              "       [2.61936963e-01],\n",
              "       [9.17368226e-08],\n",
              "       [1.51408598e-01],\n",
              "       [9.99880195e-01],\n",
              "       [1.00000000e+00],\n",
              "       [2.71854645e-07],\n",
              "       [6.95558250e-01],\n",
              "       [3.67341113e-06],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [3.37308407e-01],\n",
              "       [8.70329328e-03],\n",
              "       [9.99999762e-01],\n",
              "       [3.26025533e-04],\n",
              "       [4.55561007e-04],\n",
              "       [9.99998212e-01],\n",
              "       [9.11493589e-06],\n",
              "       [5.75248450e-05],\n",
              "       [9.99062002e-01],\n",
              "       [3.14521790e-01],\n",
              "       [5.20876706e-01],\n",
              "       [9.99987841e-01],\n",
              "       [1.73389155e-04],\n",
              "       [7.97250192e-04],\n",
              "       [6.52305171e-05],\n",
              "       [1.05664100e-09],\n",
              "       [2.12779181e-04],\n",
              "       [9.99998331e-01],\n",
              "       [6.47058926e-07],\n",
              "       [8.38555396e-01],\n",
              "       [3.27925384e-01],\n",
              "       [1.49707003e-02],\n",
              "       [6.64278865e-02],\n",
              "       [1.18924584e-06],\n",
              "       [2.90972239e-04],\n",
              "       [9.99992728e-01],\n",
              "       [9.99859691e-01],\n",
              "       [5.35223214e-03],\n",
              "       [6.22145126e-06],\n",
              "       [8.29178095e-02],\n",
              "       [1.13879128e-06],\n",
              "       [9.99749005e-01],\n",
              "       [6.58640784e-05],\n",
              "       [9.10408318e-01],\n",
              "       [9.93529022e-01],\n",
              "       [8.42809439e-01],\n",
              "       [9.84408200e-01],\n",
              "       [3.62193346e-01],\n",
              "       [7.46092945e-03],\n",
              "       [3.13035736e-04],\n",
              "       [1.00717679e-01],\n",
              "       [8.41619372e-01],\n",
              "       [9.71274436e-01],\n",
              "       [1.18411340e-01],\n",
              "       [1.05039487e-02],\n",
              "       [3.29437285e-07],\n",
              "       [3.25879846e-05],\n",
              "       [9.45226029e-02],\n",
              "       [4.88810569e-01],\n",
              "       [1.17989689e-01],\n",
              "       [9.99947548e-01],\n",
              "       [9.99982715e-01],\n",
              "       [9.54686165e-01],\n",
              "       [9.99436438e-01],\n",
              "       [3.66328396e-02],\n",
              "       [1.64800913e-05],\n",
              "       [9.99748170e-01],\n",
              "       [9.55019772e-01],\n",
              "       [2.54087587e-04],\n",
              "       [2.76901647e-02],\n",
              "       [9.79382634e-01],\n",
              "       [1.40115270e-08],\n",
              "       [7.56479502e-01],\n",
              "       [9.67348695e-01],\n",
              "       [7.70178556e-01],\n",
              "       [9.99996066e-01],\n",
              "       [4.05855298e-01],\n",
              "       [2.18157936e-03],\n",
              "       [9.49848175e-01],\n",
              "       [7.09144661e-06],\n",
              "       [3.40930149e-02],\n",
              "       [4.16522980e-01],\n",
              "       [9.21155453e-01],\n",
              "       [8.86100292e-01],\n",
              "       [1.53924047e-04],\n",
              "       [6.88489003e-04],\n",
              "       [6.16764009e-01],\n",
              "       [2.68021831e-03],\n",
              "       [1.48826832e-04],\n",
              "       [1.15044350e-05],\n",
              "       [2.43477777e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.98461366e-01],\n",
              "       [3.57848912e-01],\n",
              "       [9.99860287e-01],\n",
              "       [9.99991775e-01],\n",
              "       [1.17365824e-08],\n",
              "       [9.99994755e-01],\n",
              "       [1.06162038e-02],\n",
              "       [9.99118030e-01],\n",
              "       [3.04776460e-01],\n",
              "       [1.75292548e-02],\n",
              "       [1.76662055e-04],\n",
              "       [1.25239308e-06],\n",
              "       [5.71567379e-03],\n",
              "       [1.09183629e-05],\n",
              "       [5.94396651e-01],\n",
              "       [1.45260477e-02],\n",
              "       [9.99995470e-01],\n",
              "       [1.90754037e-03],\n",
              "       [8.12780082e-01],\n",
              "       [5.59836507e-01],\n",
              "       [6.92165573e-04],\n",
              "       [3.31653398e-03],\n",
              "       [9.99997973e-01],\n",
              "       [1.26409428e-02],\n",
              "       [9.99968171e-01],\n",
              "       [8.63904178e-01],\n",
              "       [5.61390305e-03],\n",
              "       [2.14411274e-01],\n",
              "       [4.10612032e-04],\n",
              "       [1.60300490e-02],\n",
              "       [9.99991775e-01],\n",
              "       [1.38234896e-06],\n",
              "       [2.15384760e-04],\n",
              "       [9.75648221e-03],\n",
              "       [1.00000000e+00],\n",
              "       [6.80963695e-03],\n",
              "       [5.59004329e-05],\n",
              "       [9.99907136e-01],\n",
              "       [1.88371430e-07],\n",
              "       [4.63461643e-03],\n",
              "       [1.65524349e-01],\n",
              "       [2.99099803e-01],\n",
              "       [4.24561003e-05],\n",
              "       [2.06286311e-01],\n",
              "       [3.02398354e-02],\n",
              "       [4.75287214e-02],\n",
              "       [4.65331413e-02],\n",
              "       [1.71074316e-01],\n",
              "       [4.66065947e-04],\n",
              "       [9.99478042e-01],\n",
              "       [9.98175144e-01],\n",
              "       [3.65189016e-01],\n",
              "       [4.47693492e-06],\n",
              "       [3.47920984e-04],\n",
              "       [9.99991775e-01],\n",
              "       [9.95687544e-01],\n",
              "       [1.00000000e+00],\n",
              "       [1.27861038e-01],\n",
              "       [9.99253690e-01],\n",
              "       [6.34330281e-05],\n",
              "       [9.95928943e-01],\n",
              "       [9.80781198e-01],\n",
              "       [2.75390599e-10],\n",
              "       [9.99632001e-01],\n",
              "       [1.92281250e-02],\n",
              "       [9.96197641e-01],\n",
              "       [9.99958873e-01],\n",
              "       [9.73465443e-02],\n",
              "       [3.05497379e-05],\n",
              "       [3.95731956e-01],\n",
              "       [4.57926092e-07],\n",
              "       [2.00657677e-02],\n",
              "       [1.00000000e+00],\n",
              "       [3.14268857e-01],\n",
              "       [9.98182297e-01],\n",
              "       [1.73414737e-01],\n",
              "       [9.99994278e-01],\n",
              "       [9.96019900e-01],\n",
              "       [7.96057470e-03],\n",
              "       [5.18885827e-07],\n",
              "       [9.00535583e-01],\n",
              "       [1.47220198e-04],\n",
              "       [4.63656709e-02],\n",
              "       [9.99973059e-01],\n",
              "       [9.99598682e-01],\n",
              "       [9.99999642e-01],\n",
              "       [9.99964595e-01],\n",
              "       [4.61761355e-01],\n",
              "       [9.75666761e-01],\n",
              "       [1.42469992e-06],\n",
              "       [8.30469906e-01],\n",
              "       [9.99030471e-01],\n",
              "       [9.99778211e-01],\n",
              "       [2.68813310e-05],\n",
              "       [9.61025357e-01],\n",
              "       [9.93421376e-01],\n",
              "       [7.05479819e-04],\n",
              "       [5.79063036e-03],\n",
              "       [1.18411340e-01],\n",
              "       [5.95374079e-03],\n",
              "       [8.55966330e-01],\n",
              "       [9.76571977e-01],\n",
              "       [1.00000000e+00],\n",
              "       [2.53275648e-04],\n",
              "       [1.26445059e-06],\n",
              "       [6.57715759e-07],\n",
              "       [6.03989661e-01],\n",
              "       [2.40862975e-03],\n",
              "       [1.63207259e-02],\n",
              "       [9.75757062e-01],\n",
              "       [2.76898409e-05],\n",
              "       [7.70764112e-01],\n",
              "       [8.34239926e-03],\n",
              "       [8.94849002e-01],\n",
              "       [9.99997497e-01],\n",
              "       [3.42670828e-05],\n",
              "       [9.81813192e-01],\n",
              "       [2.02912856e-02],\n",
              "       [7.27504471e-07],\n",
              "       [2.43510352e-03],\n",
              "       [1.00000000e+00],\n",
              "       [5.24987996e-01],\n",
              "       [9.00036355e-07],\n",
              "       [7.35591501e-02],\n",
              "       [6.88373029e-01],\n",
              "       [1.79436407e-04],\n",
              "       [9.99963522e-01],\n",
              "       [2.14904244e-03],\n",
              "       [9.38228190e-01],\n",
              "       [2.85859942e-01],\n",
              "       [8.11589824e-04],\n",
              "       [1.78663373e-01],\n",
              "       [3.19266230e-01],\n",
              "       [8.65652168e-04],\n",
              "       [9.99665022e-01],\n",
              "       [1.69507995e-01],\n",
              "       [7.23483264e-01],\n",
              "       [9.94822383e-01],\n",
              "       [1.97808892e-01],\n",
              "       [4.01122011e-02],\n",
              "       [1.40115270e-08],\n",
              "       [3.84642959e-01],\n",
              "       [6.05629683e-01],\n",
              "       [1.00000000e+00],\n",
              "       [9.76262629e-01],\n",
              "       [1.68450316e-03],\n",
              "       [1.00000000e+00],\n",
              "       [5.52262068e-01],\n",
              "       [9.58730936e-01],\n",
              "       [5.52262068e-01],\n",
              "       [9.99986649e-01],\n",
              "       [1.36836779e-05],\n",
              "       [5.94660901e-02],\n",
              "       [6.99472125e-08],\n",
              "       [9.99997973e-01],\n",
              "       [1.90472275e-01],\n",
              "       [8.41903873e-03],\n",
              "       [1.25139741e-06],\n",
              "       [4.89240885e-03],\n",
              "       [9.95605513e-02],\n",
              "       [4.11841465e-05],\n",
              "       [2.45613307e-01],\n",
              "       [1.87016593e-03],\n",
              "       [1.19151957e-02],\n",
              "       [7.99424112e-01],\n",
              "       [3.27383354e-03],\n",
              "       [1.62950356e-03],\n",
              "       [8.23951967e-04],\n",
              "       [4.68602153e-08],\n",
              "       [1.91090591e-02],\n",
              "       [9.91079271e-01],\n",
              "       [4.67160571e-04],\n",
              "       [3.62152942e-02],\n",
              "       [1.16012217e-02],\n",
              "       [9.90994036e-01],\n",
              "       [9.99999881e-01],\n",
              "       [1.78849659e-04],\n",
              "       [5.98684564e-05],\n",
              "       [1.69897567e-06],\n",
              "       [3.60064263e-08],\n",
              "       [9.99998450e-01],\n",
              "       [4.68602153e-08],\n",
              "       [3.83755495e-03],\n",
              "       [9.99962211e-01],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [1.00000000e+00],\n",
              "       [5.04284289e-05],\n",
              "       [7.28592713e-05],\n",
              "       [7.49836981e-01],\n",
              "       [8.09827507e-01],\n",
              "       [9.99998212e-01],\n",
              "       [6.93699598e-01],\n",
              "       [7.31610954e-01],\n",
              "       [9.73478019e-01],\n",
              "       [9.60972667e-01],\n",
              "       [8.24362360e-06],\n",
              "       [2.21439826e-08],\n",
              "       [1.07679963e-02],\n",
              "       [2.26072203e-02],\n",
              "       [4.91259561e-05],\n",
              "       [6.42922882e-04],\n",
              "       [9.99987245e-01],\n",
              "       [9.99999762e-01],\n",
              "       [9.23564312e-06],\n",
              "       [9.99918699e-01],\n",
              "       [8.44792604e-01],\n",
              "       [5.43455407e-02],\n",
              "       [2.98720971e-03],\n",
              "       [8.68471146e-01],\n",
              "       [7.37844169e-01],\n",
              "       [7.33876834e-03],\n",
              "       [8.81022629e-07]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUJopeNIQ268"
      },
      "source": [
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeLbAC4DRAyf",
        "outputId": "5986d51f-508d-43e4-f936-1ba3f368e10f"
      },
      "source": [
        "model_5_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhT0uJ2ERHhb"
      },
      "source": [
        "model_5_results = calculate_results(val_labels,\n",
        "                                    model_5_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2LS9VgzRWA3",
        "outputId": "699508db-5192-45f8-f095-1f0553ad972d"
      },
      "source": [
        "model_5_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7598425196850394,\n",
              " 'f1': array([0.78794902, 0.72314675]),\n",
              " 'precision': array([0.75723831, 0.76357827]),\n",
              " 'recall': array([0.82125604, 0.68678161])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-ZDUQUDRacT"
      },
      "source": [
        "##Model 6: Using transfer earning(using USE feature extractor)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx50QA0yR9n7"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C8Enm-0UoSd",
        "outputId": "a3672a41-c64c-4503-9743-4e1065bf44ca"
      },
      "source": [
        "#creating model using sequential api\n",
        "\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer,\n",
        "  layers.Dense(128,activation=\"relu\"),\n",
        "  layers.Dense(128,activation=\"relu\"),\n",
        "  layers.Dense(1,activation=\"sigmoid\")\n",
        "],name=\"model_6_USE\")\n",
        "\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "model_6.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 256,880,129\n",
            "Trainable params: 82,305\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS-nho19VPin",
        "outputId": "76077baf-8251-4ac4-d616-465827b940f3"
      },
      "source": [
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=10,\n",
        "                              validation_data=(val_sentences,val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(save_dir,\n",
        "                                                                     \"model_6_use\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_6_use/20210815-122022\n",
            "Epoch 1/10\n",
            "215/215 [==============================] - 7s 23ms/step - loss: 0.4732 - accuracy: 0.7827 - val_loss: 0.4401 - val_accuracy: 0.8071\n",
            "Epoch 2/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3922 - accuracy: 0.8307 - val_loss: 0.4226 - val_accuracy: 0.8136\n",
            "Epoch 3/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3643 - accuracy: 0.8437 - val_loss: 0.4241 - val_accuracy: 0.8189\n",
            "Epoch 4/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3277 - accuracy: 0.8631 - val_loss: 0.4445 - val_accuracy: 0.8176\n",
            "Epoch 5/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.2815 - accuracy: 0.8867 - val_loss: 0.4520 - val_accuracy: 0.8136\n",
            "Epoch 6/10\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.2284 - accuracy: 0.9118 - val_loss: 0.5658 - val_accuracy: 0.8031\n",
            "Epoch 7/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1830 - accuracy: 0.9330 - val_loss: 0.5673 - val_accuracy: 0.8058\n",
            "Epoch 8/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1386 - accuracy: 0.9529 - val_loss: 0.6606 - val_accuracy: 0.8163\n",
            "Epoch 9/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1101 - accuracy: 0.9628 - val_loss: 0.8377 - val_accuracy: 0.7927\n",
            "Epoch 10/10\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0868 - accuracy: 0.9724 - val_loss: 0.8746 - val_accuracy: 0.7992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCHqF1IxV3H-"
      },
      "source": [
        "model_6_pred_probs = model_6.predict(val_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5nG7THgWiQO"
      },
      "source": [
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhuGtZvOWnGU"
      },
      "source": [
        "model_6_results = calculate_results(val_labels,\n",
        "                                    model_6_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_zEBfkJWswh",
        "outputId": "563e9db7-d45a-4893-a400-10086ab2f12d"
      },
      "source": [
        "model_6_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7992125984251969,\n",
              " 'f1': array([0.83278689, 0.74876847]),\n",
              " 'precision': array([0.76047904, 0.87356322]),\n",
              " 'recall': array([0.92028986, 0.65517241])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBHxRHLrWtss"
      },
      "source": [
        "##Model 7: TF hub pretrained USE but with only 10% of the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JHHqfUbYCkP"
      },
      "source": [
        "#getting 10% of the data\n",
        "\n",
        "train_10_percent = train_df_shuffled[[\"text\",\"target\"]].sample(frac=0.1,random_state=42)\n",
        "train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
        "train_labels_10_percent = train_10_percent[\"target\"].to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-LNLSib06-6",
        "outputId": "dfe78b02-fc4c-425e-b489-9065b10337bb"
      },
      "source": [
        "# making a better 10% training data set\n",
        "train_10_percent_split = int(0.1*len(train_sentences))\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]\n",
        "len(train_sentences_10_percent),len(train_labels_10_percent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(685, 685)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv24krCgYbUw"
      },
      "source": [
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l2Itp1SZy1x",
        "outputId": "cfa8609e-d79e-453a-ab60-3a0a7cc566ec"
      },
      "source": [
        "model_7.fit(train_sentences_10_percent,\n",
        "            train_labels_10_percent,\n",
        "            epochs=5,\n",
        "            validation_data=(val_sentences,val_labels),\n",
        "            callbacks=[create_tensorboard_callback(save_dir,\n",
        "                                                   \"model_7\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_7/20210815-124720\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 1s 56ms/step - loss: 0.2237 - accuracy: 0.9372 - val_loss: 0.5758 - val_accuracy: 0.7520\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.1879 - accuracy: 0.9533 - val_loss: 0.6202 - val_accuracy: 0.7480\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.1432 - accuracy: 0.9679 - val_loss: 0.6656 - val_accuracy: 0.7520\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.1096 - accuracy: 0.9752 - val_loss: 0.7285 - val_accuracy: 0.7533\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 19ms/step - loss: 0.0783 - accuracy: 0.9869 - val_loss: 0.8122 - val_accuracy: 0.7559\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff4ecfa77d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD-_I25caHrS"
      },
      "source": [
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yquvRN1DalfB"
      },
      "source": [
        "model_7_results = calculate_results(val_labels,\n",
        "                                    model_7_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU5niIOwar_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52a00e32-f8ef-4706-c0f3-cc83f55d9132"
      },
      "source": [
        "# highly efficient than training on more data because it is going to reduce the overfitting \n",
        "model_7_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7559055118110236,\n",
              " 'f1': array([0.79194631, 0.7047619 ]),\n",
              " 'precision': array([0.7375    , 0.78723404]),\n",
              " 'recall': array([0.85507246, 0.63793103])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDoSceePautB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95300efd-d018-4531-ca77-b70c19bb01c3"
      },
      "source": [
        "model_1_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7860892388451444,\n",
              " 'f1': array([0.81828317, 0.7400319 ]),\n",
              " 'precision': array([0.75983437, 0.83154122]),\n",
              " 'recall': array([0.88647343, 0.66666667])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTIcCT0ey64q"
      },
      "source": [
        "# data leakage problem is cause because we are using the 10% of the shuffled training data set so it means that the validation data may contain some of\n",
        "# some of the cases from the 10% training data set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOk2tF_50bIJ",
        "outputId": "b76b5611-d367-488e-e345-8c302c2c9663"
      },
      "source": [
        "model_6_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7992125984251969,\n",
              " 'f1': array([0.83278689, 0.74876847]),\n",
              " 'precision': array([0.76047904, 0.87356322]),\n",
              " 'recall': array([0.92028986, 0.65517241])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCcr6xLA6BHl"
      },
      "source": [
        "model_6.save(\"model_6.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IPlKkKQ6o8D"
      },
      "source": [
        "# to load a model which has some layer from a pretrained model from tensorflow hub then we need to create custom objects \n",
        "loaded_model = tf.keras.models.load_model(\"model_6.h5\",\n",
        "                                          custom_objects={\"KerasLayer\":hub.KerasLayer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYk5ev_37KeF",
        "outputId": "f1176f0a-0be4-4328-86e3-641c3a63a9ed"
      },
      "source": [
        "loaded_model.evaluate(val_sentences,val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 1s 9ms/step - loss: 0.8746 - accuracy: 0.7992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8745608329772949, 0.7992125749588013]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Uo6z6zf7Psm",
        "outputId": "5ea43543-7a0d-4d92-d8ce-36ccf3e09317"
      },
      "source": [
        "model_6_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.7992125984251969,\n",
              " 'f1': array([0.83278689, 0.74876847]),\n",
              " 'precision': array([0.76047904, 0.87356322]),\n",
              " 'recall': array([0.92028986, 0.65517241])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_wlHTJj7Rlm"
      },
      "source": [
        "## Finding the most wrong examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RflzqY2P7ydJ"
      },
      "source": [
        "val_df = pd.DataFrame({\"Text\":val_sentences,\n",
        "                       \"Target\":val_labels,\n",
        "                       \"Prediction\":model_6_preds,\n",
        "                       \"Prediction Probability\":tf.squeeze(model_6_pred_probs)})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "3UBLZHIh9Psh",
        "outputId": "d41e2a27-2793-4ade-b56a-86b9ff912b5d"
      },
      "source": [
        "val_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Prediction Probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.038868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@camilacabello97 Internally and externally scr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.056656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Radiation emergency #preparedness starts with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.203175</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  ...  Prediction Probability\n",
              "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...  ...                0.001329\n",
              "1  FedEx no longer to transport bioterror germs i...  ...                0.038868\n",
              "2  Gunmen kill four in El Salvador bus attack: Su...  ...                0.999999\n",
              "3  @camilacabello97 Internally and externally scr...  ...                0.056656\n",
              "4  Radiation emergency #preparedness starts with ...  ...                0.203175\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00aCLwaV9bTk"
      },
      "source": [
        "most_wrong = val_df[val_df[\"Target\"]!=val_df[\"Prediction\"]].sort_values(\"Prediction Probability\",ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "tv-LTZqM-Pqs",
        "outputId": "276ecdd1-9201-4638-a524-785d968f3c02"
      },
      "source": [
        "most_wrong.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Prediction Probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>Deaths 3 http://t.co/nApviyGKYK</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.999877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>Ashes 2015: Australia¬â√õ¬™s collapse at Trent Br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.998009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>628</th>\n",
              "      <td>@noah_anyname That's where the concentration c...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.996252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.994905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.993426</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text  ...  Prediction Probability\n",
              "381                    Deaths 3 http://t.co/nApviyGKYK  ...                0.999877\n",
              "209  Ashes 2015: Australia¬â√õ¬™s collapse at Trent Br...  ...                0.998009\n",
              "628  @noah_anyname That's where the concentration c...  ...                0.996252\n",
              "31   ? High Skies - Burning Buildings ? http://t.co...  ...                0.994905\n",
              "49   @madonnamking RSPCA site multiple 7 story high...  ...                0.993426\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "L6w5M9Kq-R31",
        "outputId": "3a47ad92-5aba-4efb-d149-7a08eaa69547"
      },
      "source": [
        "most_wrong.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Target</th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Prediction Probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>@willienelson We need help! Horses will die!Pl...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>Next May I'll be free...from school from oblig...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>Plans by former First Lady and wife of ex-Pres...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>going to redo my nails and watch behind the sc...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>Just came back from camping and returned with ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Text  ...  Prediction Probability\n",
              "408  @willienelson We need help! Horses will die!Pl...  ...                0.000061\n",
              "361  Next May I'll be free...from school from oblig...  ...                0.000042\n",
              "373  Plans by former First Lady and wife of ex-Pres...  ...                0.000027\n",
              "221  going to redo my nails and watch behind the sc...  ...                0.000010\n",
              "262  Just came back from camping and returned with ...  ...                0.000007\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxnbdQcf-mCy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}